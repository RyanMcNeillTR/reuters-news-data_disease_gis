---
title: "R Notebook"
output: html_notebook
---

This notebook tests some code to iterate over the area of polygons where spillover occurrence location is approximate, as it is in most of our data to one degree or another.

This is modelled on Pigott et al's Ebola risk map.

This test file uses a synthetic data set where all but one data point is a point, and a single occurrence has a large polygon associated with it.

For speed, this file uses the 'hits' and 'controls' dataFRAMES from analysis_1.Rmd as a starting point.

rough outline:
Load shp with shapefile(s)
Flag occurrence data as point or polygon

```{r, echo = FALSE}

library(seegSDM)

library(tidymodels)
library(tidyverse)
library(data.table)

library(baguette)

library(sf)
library(rgeos)

```

Remove full covariate data set loaded in analysis_1.Rmd, if it is stil present.

```{r}

rm(long_data_joined_read)

```

Read in data from Ryan.

```{r}

raw_occ <- readRDS("C:/Users/0146156/Documents/mb_checks/all_combined.rds")

occ <- raw_occ %>% 
  mutate(poly = ifelse(str_detect(precision, "[Cc]entroid"), TRUE, FALSE))
              

```

Load 5km raster template.

```{r}

library(raster)

template <- raster("C:/Users/0146156/Documents/mb_checks/hansen_datamask.tif")

```

Generate artificial absence records and a fictional covariate.

```{r}
library(dismo)

set.seed(123)

tmp <- randomPoints(template, 1000)

bg <- tmp %>% as_tibble() %>% 
  mutate(spillover = FALSE) %>%
  rowid_to_column("rowid") %>%
  mutate(fic_cov = runif(nrow(bg), 1, 10)) %>%
  select(rowid, spillover, fic_cov, x, y)

```

For now, we are going to create our shapefile dataframe 'shp' by associating the first two Bangladesh hits in the database to the shapefiles for Baliadangi and Rajshashi. THIS IS COMPLETE FICTION, FOR THE PURPOSES OF CODE DEVELOPMENT.

Note the structure of the shapefile dataframe here: first column rowid, second is poly_geom.

```{r}

grab_polygon <-function(geom, id) {
  geom %>% dplyr::select(poly_geom = geom) %>% 
           mutate(point_geom = st_centroid(poly_geom),
                  precision = "centroid",
                  reuters_id = id,
                  country_iso = "BGD")
}

bgd_gadm_2 <- st_read("./input_data/Bangladesh/gadm/gadm36_BGD_gpkg/gadm36_BGD.gpkg",
                      layer = "gadm36_BGD_2") %>%
              janitor::clean_names()

bgd_gadm_3 <- st_read("./input_data/Bangladesh/gadm/gadm36_BGD_gpkg/gadm36_BGD.gpkg",
                      layer = "gadm36_BGD_3") %>%
              janitor::clean_names()

bgd_6 <- bgd_gadm_3 %>%
  filter(str_detect(name_3, "Baliadangi")) %>%
  grab_polygon(6) %>%
  dplyr::select(poly_geom) %>%
  mutate(rowid = "4435529") %>%
  dplyr::select(rowid, poly_geom)

bgd_90 <- bgd_gadm_2 %>% 
  filter(str_detect(name_2, "Rajshahi")) %>%
  grab_polygon(90) %>%
  dplyr::select(poly_geom) %>%
  mutate(rowid = "4448154") %>%
  dplyr::select(rowid, poly_geom)

shp <- rbind(bgd_6, bgd_90)

rm(bgd_6, bgd_90, bgd_gadm_2, bgd_gadm_3)

shp

```

Flag our two fictional poly occurrence as poly = TRUE and create a data frames of polygon occurrences only and point occurrences only. 

```{r}

dat <- hits %>% 
  mutate(poly = ifelse(rowid == "4435529" | rowid == "4448154", TRUE, FALSE)) 

dat_poly <- dat %>% filter(poly) 
dat_pt <- dat %>% filter(!poly)

dat_pt

```

Load raster template.

```{r}

template <- raster("C:/Users/0146156/Documents/mb_checks/hansen_datamask.tif")

```

Use lapply to loop over each row in shp, our dataframe of polygons, and create lists of coordinates associated with the polygons.

```{r}

pt_list <- lapply(1:nrow(shp),

  function(i, shp, template) {
    poly <- shp[i, ] #  grab one polygon
    
    # buffer to cover the center of at least one pixel - we may not need this
    #d <- sqrt(2 * 2500 ^ 2) + 1
    #d <- d * 10 ^ -5 # rough conversion to decimal degrees
    #poly <- gBuffer(poly, width = d)
    
    # rasterize the polygon and get coordinates
    tmp <- rasterize(poly, template)
    pts <- xyFromCell(tmp, which(!is.na(getValues(tmp))))
    
    return (pts)
    
  },

  shp, template)

pt_list

```
Loop through our polygon shapefile shp and create a new dataframe where each coordinate has its own row and other variables are duplicated, for sampling purposes later.

*** This will work once dat_new has lat/long values as well (and migh tneed to fix names etc)

```{r}

# starting a new data frame that will contain both points and polygons 
# weights are always 1 for point occurrences 
dat_new <- dat_pt %>% mutate(wt = 1)

# loop through polygon dataframe again
for(i in 1:nrow(shp)) {
  
  # pull the rowid, points associated with this occurrence and point count 
  rowid <- shp$rowid[i]
  #rowid
  
  pts <- pt_list[[i]]
  #pts
  
  n <- nrow(pts)
  #n
  
  # return a warning if no points were found 
  #if (n == 0) {
  #  warning(paste("Polygon for occurrence ", rowid, "returned zero coordinates!" )
  #  break
  #}
  
  # pull other data and repeat it to match each point 
  info <- dat_poly[i, ]
  info_repeat <- info[rep(1:nrow(info), each = n), ]
  
  # add weights
  info_repeat$wt <- 1/n
  
  # add coordinates
  final <- cbind(info_repeat, pts)
  
  dat_new <- rbind(dat_new, final)
  
}

```


