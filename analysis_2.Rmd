---
title: "R Notebook"
output: html_notebook
---

This notebook tests some code to iterate over the area of polygons where spillover occurrence location is approximate, as it is in most of our data to one degree or another.

This is modelled on Pigott et al's Ebola risk map.

This test file uses a synthetic data set where all but one data point is a point, and a single occurrence has a large polygon associated with it.

For speed, this file uses the 'hits' and 'controls' dataFRAMES from analysis_1.Rmd as a starting point.

rough outline:
Load shp with shapefile(s)
Flag occurrence data as point or polygon

```{r, echo = FALSE}

library(seegSDM)

library(tidymodels)
library(tidyverse)
library(data.table)

library(baguette)

library(sf)
library(rgeos)

```

Remove full covariate data set loaded in analysis_1.Rmd, if it is stil present.

```{r}

rm(long_data_joined_read)

```

Read in data from Ryan, convert points object into coordinates and flag occurrences that are coded to polygons based on whether their point is a centroid or not. 

```{r}

raw_occ <- readRDS("C:/Users/0146156/Documents/mb_checks/all_combined.rds")

coords <- raw_occ$point_geom %>% st_coordinates()

hits <- raw_occ %>% 
  mutate(poly = ifelse(str_detect(precision, "[Cc]entroid"), TRUE, FALSE)) %>%
  cbind(coords)

hits %>% st_drop_geometry() %>% group_by(poly) %>% count
hits %>% st_drop_geometry() %>% filter(is.na(poly))

# separate hits into poly and point data frames 
dat_poly <- hits %>% filter(poly)
dat_pt <- hits %>% filter(!poly)

```

Load 5km raster template.

```{r}

library(raster)

template <- raster("C:/Users/0146156/Documents/mb_checks/hansen_datamask.tif")

```

Generate artificial absence records and a fictional covariate.

```{r}
library(dismo)

set.seed(123)

tmp <- randomPoints(template, 1000)

bg <- tmp %>% as_tibble() %>% 
  mutate(spillover = FALSE) %>%
  rowid_to_column("rowid") %>%
  mutate(fic_cov = runif(nrow(bg), 1, 10)) %>%
  select(rowid, spillover, fic_cov, x, y)

```

Use lapply to loop over each row in shp, our dataframe of polygons, and create lists of coordinates associated with the polygons.

This first time through we will do it with no buffer and see how many pixels are covered.

```{r}

shp <- st_sf(dat_poly$poly_geom, crs = 4326)

pt_list <- lapply(1:nrow(shp),

  function(i, shp, template) {
    poly <- shp[i, ] #  grab one polygon
    
    # rasterize the polygon and get coordinates
    tmp <- rasterize(poly, template)
    pts <- xyFromCell(tmp, which(!is.na(getValues(tmp))))
    
    return (pts)
    
  },

  shp, template)

pixel_count <- lengths(pt_list)/2

area <- st_area(shp)

stats_no_buffer <- cbind(dat_poly$id, pixel_count, area) %>% as_tibble() %>%
  rename(id = V1) %>%
  mutate(pixels = as.integer(pixel_count), sq_km = as.numeric(area)/1000) %>%
  select(-pixel_count, -area) %>%
  arrange(desc(sq_km))
  
write.csv(stats_no_buffer, "stats_no_buffer.csv")

```

Loop through to build the point list again, but this time with buffers, and assess resulting pixel overlap and area. 

```{r}

shp <- st_sf(dat_poly$poly_geom, crs = 4326)

pt_list <- lapply(1:nrow(shp),

  function(i, shp, template) {
    poly <- shp[i, ] #  grab one polygon
    
    # buffer the polygon so it covers at least one pixel 
    poly <- poly %>% st_transform(8857) %>% 
      st_buffer(3535) %>% 
      st_transform(4326)
    
    # rasterize the polygon and get coordinates
    tmp <- rasterize(poly, template)
    pts <- xyFromCell(tmp, which(!is.na(getValues(tmp))))
    
    return (pts)
    
  },

  shp, template)

pixel_count <- lengths(pt_list)/2

stats_buffer <- cbind(dat_poly$id, pixel_count, area) %>% as_tibble() %>%
  rename(id = V1) %>%
  mutate(pixels = as.integer(pixel_count), sq_km = as.numeric(area)/1000) %>%
  select(-pixel_count, -area) %>%
  arrange(desc(sq_km))
  
write.csv(stats_buffer, "stats_buffer.csv")

```

Loop through our polygon shapefile shp and create a new dataframe where each coordinate has its own row and other variables are duplicated, for sampling purposes later.

```{r}

# starting a new data frame that will eventually have points and polygons 
# weights are always 1 for point occurrences 
dat_new <- dat_pt %>% 
  select(-point_geom) %>%
  st_drop_geometry() %>% 
  mutate(wt = 1)

# to run the loop below, we need a simpler version of polygon occurrences
polys_simple <- dat_poly %>% st_drop_geometry() %>% 
  select(-point_geom, -X, -Y)

# loop through polygons again
for(i in 1:nrow(polys_simple)) {

  # pull the rowid, points associated with this occurrence and point count 
  id <- polys_simple$id[i]
  pts <- pt_list[[i]]
  n <- nrow(pts)
  
  # pull other data and repeat it to match each point 
  info <- polys_simple[i, ]
  info_repeat <- info[rep(1:nrow(info), each = n), ]
  
  # add weights
  info_repeat$wt <- 1/n
  
  # add coordinates
  final <- cbind(info_repeat, pts) %>%
    rename(X = x, Y = y) %>%
    select(precision:poly, X, Y, wt)
  
  dat_new <- rbind(dat_new, final)
  
}

dat_new %>% str

```



